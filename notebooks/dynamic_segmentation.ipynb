{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.insert(0,'../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IO import*\n",
    "from data import* \n",
    "from Unet_models import*\n",
    "from segmentation import*\n",
    "\n",
    "import h5py as h5\n",
    "import patchify as patch\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 11:32:31.636555: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-21 11:32:32.662115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14635 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:61:00.0, compute capability: 7.0\n",
      "2022-03-21 11:32:32.663017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14635 MB memory:  -> device: 1, name: Tesla V100-PCIE-16GB, pci bus id: 0000:db:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "# check availible GPUS and set memory growth \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPUs will likely run quickly with dtype policy mixed_float16 as they all have compute capability of at least 7.0\n"
     ]
    }
   ],
   "source": [
    "# set mixed precision (32/16 bit) presision\n",
    "tf.keras.mixed_precision.experimental.set_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Unet_segmentation(patch_data, model, batch_size):\n",
    "    segmented = np.zeros(patch_data.shape, dtype = np.float32)\n",
    "    # check noramalization\n",
    "    if (patch_data.max() > 1):\n",
    "        patch_data = patch_data / patch_data.max()\n",
    "    # reshape patch data [nz,nx,ny,z,x,y] to [N,z,x,y]\n",
    "    N = patch_data.shape[0] * patch_data.shape[1] * patch_data.shape[2]\n",
    "    patch_data_merged = patch_data.reshape((N, patch_data.shape[3], patch_data.shape[4], patch_data.shape[5]))\n",
    "    # segment patch_data\n",
    "    patch_data_merged  = np.reshape(patch_data_merged, patch_data_merged.shape + (1,))\n",
    "    result = model.predict(patch_data_merged, verbose=1, batch_size = batch_size)\n",
    "    segmented = result.reshape(patch_data.shape)\n",
    "    return segmented\n",
    "\n",
    "def GMM_predict_labels(model, data, data_1d, ids_zero, mask):\n",
    "    result = np.zeros(data.shape, dtype = np.uint8)\n",
    "    # predict labels\n",
    "    gmm_labels = model.predict(np.expand_dims(data_1d,1))\n",
    "    # reshape 1D arr with labels to 3D mask \n",
    "    result[np.where(data != 0)] = gmm_labels + 1\n",
    "    result = result + mask\n",
    "    result[ids_zero] = 2 \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = circle_mask(size = 1224, radius = 599)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load one dataset from dynamic data\n",
    "data_path = '/home/m_fokin/NN/Data/data_exp2/exp2_time_19p6_101_102_107to110_113to185.h5'\n",
    "f =h5.File(data_path,'r')\n",
    "dsets = list(f.keys())\n",
    "\n",
    "model = UNet_3D(input_size = (256,256,256,1))\n",
    "model.load_weights(\"/home/m_fokin/NN/Unet_3D_2D/UNet_3D__16_256.hdf5\")\n",
    "\n",
    "# parameters\n",
    "batch_size = 1\n",
    "data_step = 50 \n",
    " \n",
    "for dset in tqdm(dsets): \n",
    "\n",
    "    \n",
    "    data = np.array(f[dset], dtype = np.uint8)\n",
    "    ids_zero = np.where(data == 0)\n",
    "\n",
    "    # convert data to data patches with size 256x256x256x and overlapping 128x242x242\n",
    "    patch_data = patch.patchify(data, (256, 256, 256), (128, 242, 242))\n",
    "    segmented_data = Unet_segmentation(patch_data, model, batch_size)\n",
    "\n",
    "    # reconstruct data from data patches \n",
    "    recon = recon_3D(data_patches = segmented_data, patch_step = (128,242,242), patch_size = (256, 256, 256), recon_shape = (512, 1224, 1224))\n",
    "    recon[recon >= 0.8] = 1 \n",
    "    recon[recon < 0.8] = 0 \n",
    "\n",
    "    # Fit GMM\n",
    "    data_1d = data.ravel()\n",
    "    data_1d = data_1d[data_1d != 0] \n",
    "    gmm = GaussianMixture(n_components = 4, max_iter=200, tol=1e-3, covariance_type = 'full', verbose = 0)               \n",
    "    gmm = gmm.fit(X = np.expand_dims(data_1d[::data_step],1))\n",
    "    \n",
    "    # predict labels\n",
    "    labels = GMM_predict_labels(gmm,data, data_1d , ids_zero, mask)\n",
    " \n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aea1bf3ec5772a80b962deecc6c0ec75f9b5b7fca332bab648bba035e487f582"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('TF': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
